{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ef33b33-4f08-4fac-b9d4-14dee5240713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 50ms/step - accuracy: 0.0416 - loss: 6.9401\n",
      "Epoch 2/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 0.0677 - loss: 6.2561\n",
      "Epoch 3/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.1014 - loss: 5.8055\n",
      "Epoch 4/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 51ms/step - accuracy: 0.1182 - loss: 5.4872\n",
      "Epoch 5/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.1314 - loss: 5.2150\n",
      "Epoch 6/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.1435 - loss: 4.9769\n",
      "Epoch 7/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 50ms/step - accuracy: 0.1557 - loss: 4.7537\n",
      "Epoch 8/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.1629 - loss: 4.5561\n",
      "Epoch 9/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.1748 - loss: 4.3496\n",
      "Epoch 10/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.1833 - loss: 4.1422\n",
      "Epoch 11/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.2025 - loss: 3.9355\n",
      "Epoch 12/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.2217 - loss: 3.7476\n",
      "Epoch 13/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.2473 - loss: 3.5584\n",
      "Epoch 14/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.2733 - loss: 3.3701\n",
      "Epoch 15/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 48ms/step - accuracy: 0.2992 - loss: 3.1820\n",
      "Epoch 16/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.3296 - loss: 3.0038\n",
      "Epoch 17/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.3524 - loss: 2.8520\n",
      "Epoch 18/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.3776 - loss: 2.7037\n",
      "Epoch 19/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.4030 - loss: 2.5599\n",
      "Epoch 20/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.4245 - loss: 2.4415\n",
      "Epoch 21/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.4515 - loss: 2.3076\n",
      "Epoch 22/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.4736 - loss: 2.1910\n",
      "Epoch 23/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.4970 - loss: 2.0743\n",
      "Epoch 24/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.5113 - loss: 1.9999\n",
      "Epoch 25/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.5358 - loss: 1.8810\n",
      "Epoch 26/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.5578 - loss: 1.7718\n",
      "Epoch 27/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.5722 - loss: 1.7058\n",
      "Epoch 28/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.5911 - loss: 1.6187\n",
      "Epoch 29/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.6107 - loss: 1.5341\n",
      "Epoch 30/30\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.6257 - loss: 1.4677\n",
      "harry was scared toward the table and turned on the step call him “professor harry ” said hagrid coolly but tell him — perhaps your name ” said hagrid quickly “a good ” said professor mcgonagall breathing heavily later “all right boil harry ” said hermione fiercely “we’ve got to go ” dumbledore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,SimpleRNN, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Load text\n",
    "def load_data(file_path):\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        text=f.read()\n",
    "    return text\n",
    "\n",
    "filePath='HarryPotterPart1.txt'\n",
    "text=load_data(filePath).lower()\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>') # Out-Of-Vocabulary token\n",
    "                                        # If a word not seen during training appears later, it will be replaced with <OOV>\n",
    "                                        # Helps handle unknown words instead of ignoring them\n",
    "tokenizer.fit_on_texts([text]) # analyzes the input text and creates a word index (mapping of words to unique integers)\n",
    "total_words = len(tokenizer.word_index) + 1 #  0 is usually reserved for padding\n",
    "\n",
    "\n",
    "# Convert text to sequences\n",
    "input_sequences = []\n",
    "tokens = tokenizer.texts_to_sequences([text])[0] # converts the input text into a list of numbers based on the word index\n",
    "# if we were training tokenizer on more than 1 text, then for whichever text we require tokens we will take it from above line\n",
    "\n",
    "seq_length = 50  # Each input sequence contains 50 words\n",
    "\n",
    "# First seq_length tokens (input): Used for training the model.\n",
    "# Last token (target): Used as the label the model tries to predict.\n",
    "# so total of (50 + 1) in one input_sequence index\n",
    "\n",
    "for i in range(seq_length, len(tokens)):\n",
    "    input_sequences.append(tokens[i - seq_length:i + 1])\n",
    "\n",
    "# Pad sequences and split inputs/targets\n",
    "# after this X will have inputs and y will have label for those inputs\n",
    "\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length + 1, padding='pre'))\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "\n",
    "# One-hot encode the labels , note- there are other ways for\n",
    "# encoding like pre-trained word2vec encoding and so on\n",
    "\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
    "\n",
    "# Build the Simple RNN model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=64, input_length=seq_length),  # Word embeddings\n",
    "    SimpleRNN(256, return_sequences=False),  # RNN Layer\n",
    "    Dense(256, activation='relu'),  # Fully Connected Layer\n",
    "    Dense(total_words, activation='softmax')  # Output Layer\n",
    "])\n",
    "\n",
    "# 256 in RNN - The number of hidden units (size of the hidden state vector)\n",
    "# return_sequences=False  - The RNN will only return the final hidden state after processing the entire sequence\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=30, batch_size=128)\n",
    "\n",
    "\n",
    "# Function to generate text using RNN\n",
    "def generate_text(seed_text, next_words=50):\n",
    "    for _ in range(next_words):\n",
    "        tokenized_input = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        tokenized_input = pad_sequences([tokenized_input], maxlen=seq_length, padding='pre')\n",
    "\n",
    "        predicted_probs = model.predict(tokenized_input, verbose=0)\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        predicted_word = tokenizer.index_word.get(predicted_index, \"<OOV>\")\n",
    "\n",
    "        seed_text += \" \" + predicted_word\n",
    "    return seed_text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b3eecb9-3485-46db-93f9-53f77d4e1974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry is so cute and buy the ‘gar’ “dumbledore ” he said finally “no we’ll ignore the letter from ter the first question he said and stopped out of the hut of his bed “merry christmas ” he said “no ” said hermione “i don’t care about the train ” he ignored them two identical\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate text using the trained model\n",
    "print(generate_text(\"Harry is so cute and\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "425d0f32-1f77-4c4e-9fae-5dddbed0aa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 248ms/step - accuracy: 0.0409 - loss: 7.0609\n",
      "Epoch 2/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 281ms/step - accuracy: 0.0528 - loss: 6.3783\n",
      "Epoch 3/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 343ms/step - accuracy: 0.0758 - loss: 6.0866\n",
      "Epoch 4/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 381ms/step - accuracy: 0.0983 - loss: 5.7929\n",
      "Epoch 5/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 388ms/step - accuracy: 0.1112 - loss: 5.6045\n",
      "Epoch 6/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m642s\u001b[0m 1s/step - accuracy: 0.1229 - loss: 5.3776\n",
      "Epoch 7/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 280ms/step - accuracy: 0.1281 - loss: 5.2047\n",
      "Epoch 8/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 281ms/step - accuracy: 0.1380 - loss: 5.0227\n",
      "Epoch 9/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 311ms/step - accuracy: 0.1455 - loss: 4.8957\n",
      "Epoch 10/10\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 367ms/step - accuracy: 0.1517 - loss: 4.7298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x13b8f3c9700>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "\n",
    "# load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path,'r',encoding='utf-8') as f:\n",
    "        text=f.read()\n",
    "    return text\n",
    "\n",
    "text=load_data('HarryPotterPart1.txt').lower()\n",
    "\n",
    "#tokenize data\n",
    "tokenizer=Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts([text])\n",
    "totalWords=len(tokenizer.word_index)+1;\n",
    "\n",
    "# Convert text into sequences\n",
    "input_sequences = []\n",
    "tokens = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "seq_len=50\n",
    "\n",
    "for i in range (seq_len, len(tokens)):\n",
    "    input_sequences.append(tokens[i-seq_len: i+1])\n",
    "\n",
    "input_sequences=np.array(input_sequences)\n",
    "X,Y= input_sequences[:,:-1], input_sequences[:,-1]\n",
    "Y=tf.keras.utils.to_categorical(Y, num_classes=totalWords)\n",
    "\n",
    "model=Sequential([\n",
    "    Embedding(input_dim=totalWords, output_dim=100),\n",
    "    LSTM(256, return_sequences=True),\n",
    "    LSTM(256),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X,Y, epochs=10,  batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3c873c71-dedb-494e-a4a0-2e7b9bce070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harry loves hermione ” said ron impatiently — you get me ” said ron “but “knuts ” said ron but harry shared his own chat said ron had been not on a very muggle badge and join you all by your way in the library seemed in the hospital umbrella on the window\n"
     ]
    }
   ],
   "source": [
    "def generate_LSTM(seed_text, next_words=50, temperature=0.7):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
    "\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_probs = np.log(predicted_probs) / temperature  # Adjust randomness\n",
    "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
    "        predicted_index = np.random.choice(range(len(predicted_probs)), p=predicted_probs)\n",
    "\n",
    "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
    "        seed_text += \" \" + output_word\n",
    "\n",
    "    return seed_text\n",
    "\n",
    "# Generate text\n",
    "print(generate_LSTM(\"harry loves hermione\",next_words=50, temperature=0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434a5b1-da17-4b30-ab94-e533b0cda908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
